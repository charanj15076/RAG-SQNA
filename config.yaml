model_path:
   large: "./models/mistral-7b-instruct-v0.1.Q5_K_M.gguf"
  
model_type : "mistral"
model_config:
   'max_new_tokens' : 256
   'temperature' : 0.2
   'context_length' : 2048
   'gpu_layers' : 0
   'threads' : -1

chat_config:
   chat_memory_length: 2
   number_of_retrieved_documents: 3

pdf_text_splitter:
   chunk_size: 1024
   overlap : 50
   seperators: ["\n","\n\n"]

llava_model:
   llava_model_path : "./models/ggml-model-q5_k.gguf"
   chip_model_path : "./models/mmproj-model-f16.gguf"


embeddings_path : "BAAI/bge-large-en-v1.5"

model_config : {'max_new_tokens' : 512, 'temperature' : 0, 'context_length' : 4096, 'gpu_layers': 0}

chat_history_path: "./chat_sessions/"